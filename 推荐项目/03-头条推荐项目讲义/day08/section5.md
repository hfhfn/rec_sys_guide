# 8.5 深度学习CTR排序模型

## 学习目标

- 目标
  - 知道深度学习排序模型的发展特点
- 应用
  - 无

### 8.5.1 深度学习CTR模型的前夜

2010年FM被提出，特征交叉的概念被引入CTR模型；2012年MLR在阿里大规模应用，其结构十分接近三层神经网络；2014年Facebook用GBDT处理特征，揭开了特征工程模型化的篇章。这些概念都将在深度学习CTR模型中继续应用，持续发光。

另一边，Alex Krizhevsky 2012年提出了引爆整个深度学习浪潮的AlexNet，深度学习的大幕正式拉开，其应用逐渐从图像扩展到语音，再到NLP领域，推荐和广告也必然会紧随其后，投入深度学习的大潮之中。

2016年，随着FNN，Deep&Wide，Deep crossing等一大批优秀的CTR模型框架的提出，深度学习CTR模型逐渐席卷了推荐和广告领域，成为新一代CTR模型当之无愧的主流。

#### 深度学习CTR算法演化图

![](../images/深度学习CTR演化关系图.png)

我们在学习使用一些广告、推荐领域流行的深度学习CTR模型的结构特点时候。应当选择模型的标准尽量遵循下面三个原则：

* 1.模型的在业界影响力较大的

* 2.已经被Google，微软，阿里等知名互联网公司成功应用的

* 3.工程导向的，而不是仅用实验数据验证或学术创新用的

#### DNN

**实验表明从线性的LR到具备非线性交叉的FM，到具备Field信息交叉的FFM**，模型复杂度（模型容量）的提升，带来的都是结果的提升。而LR和FM/FFM可以视作简单的浅层神经网络模型，基于下面一些考虑，我们在把CTR模型切换到深度学习神经网络模型：

- 通过改进模型结构，**加入深度结构，利用端到端的结构挖掘高阶非线性特征**，以及浅层模型无法捕捉的潜在模式。
- 对于某些ID类特别稀疏的特征，可以在模型中学习到保持分布关系的稠密表达（embedding）。
- 充分利用图片和文本等在简单模型中不好利用的信息。

#### **Google Wide&Deep（2016年）记忆能力和泛化能力的综合权衡**

首先尝试的是Google提出的经典模型Wide & Deep Model，模型包含Wide和Deep两个部分(LR+DNN的结合)

- 其中Wide部分可以很好地学习样本中的高频部分，在LR中使用到的特征可以直接在这个部分使用，但对于没有见过的ID类特征，模型学习能力较差，同时合理的人工特征工程对于这个部分的表达有帮助。
  - **根据人工经验、业务背景，将我们认为有价值的、显而易见的特征及特征组合，喂入Wide侧**。
- Deep部分可以补充学习样本中的长尾部分，同时提高模型的泛化能力。Wide和Deep部分在这个端到端的模型里会联合训练。
  - **通过embedding将tag向量化，变tag的精确匹配，为tag向量的模糊查找，使自己具备了良好的“扩展”能力**。

![](../images/宽深度组合.png)

Wide&Deep对之后模型的影响在于——大量深度学习模型采用了两部分甚至多部分组合的形式，利用不同网络结构挖掘不同的信息后进行组合，充分利用和结合了不同网络结构的特点。

#### 阿里DIN（2018年）阿里加入Attention机制的深度学习网络