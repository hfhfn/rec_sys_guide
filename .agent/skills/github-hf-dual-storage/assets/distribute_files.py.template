#!/usr/bin/env python3
"""
Dual-Storage Distribution Script v3.0
- Scans project for large files (>50MB).
- Uploads large files to HuggingFace (${HF_USERNAME}/${HF_REPO_NAME}).
- Sync Deletion: Cleans up redundant files on HF that are deleted locally.
- Enhances manifest with metadata (extension, last modified).
- Syncs .gitignore and removes large files from Git index.
"""
import os
import sys
import json
import subprocess
from pathlib import Path
from datetime import datetime

# --- Configuration ---
SIZE_THRESHOLD = 50 * 1024 * 1024  # 50MB
HF_REPO_ID = "${HF_USERNAME}/${HF_REPO_NAME}"  # Agent: Replace this!
PROJECT_ROOT = Path(__file__).resolve().parent.parent

# Exclude directories
EXCLUDE_DIRS = {'.git', '.idea', '.vscode', 'venv', 'node_modules', '__pycache__', '.serena', '.github'}

def get_file_size(path):
    return path.stat().st_size

def run_git_cmd(args):
    try:
        subprocess.run(['git'] + args, cwd=PROJECT_ROOT, check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    except Exception:
        pass

def scan_files():
    large_files = []
    small_files = []
    print(f"ðŸ” Scanning files (Threshold: {SIZE_THRESHOLD/1024/1024:.0f}MB)...")

    for path in PROJECT_ROOT.rglob('*'):
        if not path.is_file(): continue
        parts = path.relative_to(PROJECT_ROOT).parts
        if any(p.startswith('.') and p not in ['.gitignore', '.gitattributes'] for p in parts): continue
        if any(ex in parts for ex in EXCLUDE_DIRS): continue

        try:
            size = get_file_size(path)
            if size >= SIZE_THRESHOLD:
                large_files.append(path)
            else:
                small_files.append(path)
        except OSError: pass

    return large_files, small_files

def upload_to_hf(files):
    if not files: return
    print(f"\nðŸš€ Uploading {len(files)} large files to HuggingFace ({HF_REPO_ID})...")
    try:
        from huggingface_hub import HfApi
        api = HfApi()
        user = api.whoami()
        print(f"   Logged in as: {user['name']}")

        for file_path in files:
            rel_path = file_path.relative_to(PROJECT_ROOT).as_posix()
            print(f"   ðŸ“¤ Uploading: {rel_path} ({get_file_size(file_path)/1024/1024:.1f} MB)")
            api.upload_file(
                path_or_fileobj=str(file_path),
                path_in_repo=rel_path,
                repo_id=HF_REPO_ID,
                repo_type="dataset",
                commit_message=f"Upload large file: {os.path.basename(rel_path)}"
            )
        print("âœ… Upload complete")
        return True
    except ImportError:
        print("âŒ Error: huggingface_hub not installed. Run: pip install huggingface_hub")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ Upload error: {str(e)}")
        return False

def sync_hf_deletions(local_large_files):
    """Sync deletion: If a file exists on HF but is deleted locally, remove from HF"""
    print(f"\nðŸ§¹ Checking for redundant files on HuggingFace ({HF_REPO_ID})...")
    try:
        from huggingface_hub import HfApi, list_repo_files
        api = HfApi()
        remote_files = list_repo_files(repo_id=HF_REPO_ID, repo_type="dataset")
        local_rel_paths = {f.relative_to(PROJECT_ROOT).as_posix() for f in local_large_files}

        to_delete = []
        for rf in remote_files:
            if rf in local_rel_paths: continue
            if rf.endswith(('.gitattributes', 'README.md', '.gitignore')): continue
            to_delete.append(rf)

        if to_delete:
            print(f"   Found {len(to_delete)} redundant files, deleting from HF...")
            for rf in to_delete:
                print(f"   ðŸ—‘ï¸  Deleting: {rf}")
                api.delete_file(
                    path_in_repo=rf,
                    repo_id=HF_REPO_ID,
                    repo_type="dataset",
                    commit_message=f"Sync delete: {os.path.basename(rf)}"
                )
            print(f"âœ… Sync deletion complete (Removed {len(to_delete)} files)")
        else:
            print("   âœ¨ Remote repo is up to date, no redundant files found.")
    except Exception as e:
        print(f"âš ï¸ Sync deletion failed: {str(e)}")

def update_gitignore_and_git(large_files):
    if not large_files: return
    print("\nðŸ›¡ï¸  Processing Git tracking & .gitignore...")
    gitignore_path = PROJECT_ROOT / '.gitignore'

    existing_content = []
    if gitignore_path.exists():
        with open(gitignore_path, 'r', encoding='utf-8') as f:
            existing_content = f.readlines()

    header = "# [Auto] Large files managed by HuggingFace\n"
    new_content = []
    in_auto_section = False
    for line in existing_content:
        if line == header:
            in_auto_section = True
            continue
        if in_auto_section and line.strip() == "":
            in_auto_section = False
            continue
        if not in_auto_section:
            new_content.append(line)

    new_rules = []
    for file_path in large_files:
        rel_path = file_path.relative_to(PROJECT_ROOT).as_posix()
        new_rules.append(rel_path)
        run_git_cmd(['rm', '--cached', str(file_path)])

    with open(gitignore_path, 'w', encoding='utf-8') as f:
        f.writelines(new_content)
        if new_rules:
            if new_content and not new_content[-1].endswith('\n'): f.write('\n')
            f.write("\n" + header)
            for rule in sorted(new_rules):
                f.write(f"{rule}\n")
    print(f"   ðŸ“ Updated .gitignore with {len(new_rules)} rules")

def generate_manifest(large_files):
    print("\nðŸ“‹ Generating enhanced manifest (data/file_manifest.json)...")
    manifest = {
        "hf_repo_id": HF_REPO_ID,
        "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "files": []
    }

    for file_path in large_files:
        rel_path = file_path.relative_to(PROJECT_ROOT).as_posix()
        size_mb = get_file_size(file_path) / (1024 * 1024)
        hf_url = f"https://huggingface.co/datasets/{HF_REPO_ID}/resolve/main/{rel_path}"

        manifest["files"].append({
            "name": file_path.name,
            "path": rel_path,
            "extension": file_path.suffix.lower().lstrip('.'),
            "size_mb": round(size_mb, 2),
            "url": hf_url,
            "last_modified": datetime.fromtimestamp(file_path.stat().st_mtime).strftime("%Y-%m-%d %H:%M:%S")
        })

    manifest_dir = PROJECT_ROOT / 'data'
    manifest_dir.mkdir(exist_ok=True)
    with open(manifest_dir / 'file_manifest.json', 'w', encoding='utf-8') as f:
        json.dump(manifest, f, ensure_ascii=False, indent=2)
    print("âœ… Manifest generated")

def main():
    large, small = scan_files()
    print(f"   -> Found {len(large)} large files, {len(small)} small files")

    if large:
        upload_to_hf(large)
        sync_hf_deletions(large)
        update_gitignore_and_git(large)
        generate_manifest(large)
    else:
        print("ðŸŽ‰ No files > 50MB found.")
        sync_hf_deletions([])
        generate_manifest([])

    print("\nâœ… All steps complete! Ready for git push.")

if __name__ == "__main__":
    main()
